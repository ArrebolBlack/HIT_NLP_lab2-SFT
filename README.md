# HIT NLP Course 2025 Autumn - Experiment 2: LLM SFT with Local Data

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-green.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)

å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†è¯¾ç¨‹2025ç§‹å­£å­¦æœŸå®éªŒäºŒï¼šæ„å»ºæœ¬åœ°æ•°æ®å¹¶å¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€‚

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„LLMç›‘ç£å¾®è°ƒpipelineï¼ŒåŒ…å«æ•°æ®ç”Ÿæˆã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†å…¨æµç¨‹ã€‚é€šè¿‡ç»“åˆæœ¬åœ°ç”Ÿæˆçš„é¢†åŸŸç‰¹å®šæ•°æ®å’Œå¼€æºæ•°æ®é›†ï¼Œå¯¹MiniCPM4åŸºåº§æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œæ¢ç´¢SFTå¯¹æ¨¡å‹æ€§èƒ½çš„æå‡æ•ˆæœã€‚

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- ğŸ”„ å®Œæ•´çš„SFTè®­ç»ƒpipeline
- ğŸ“Š æ··åˆæ•°æ®é›†ç­–ç•¥ï¼ˆæœ¬åœ°ç”Ÿæˆ + å¼€æºæ•°æ®ï¼‰
- ğŸš€ æ”¯æŒå¤šç§è®­ç»ƒæ–¹å¼ï¼ˆFullã€LoRAã€QLoRAï¼‰
- ğŸ¤– å¤šæ¡†æ¶æ¨ç†æ”¯æŒï¼ˆTransformersã€vLLMã€SGLangï¼‰
- âš¡ é«˜æ•ˆçš„å¼‚æ­¥æ•°æ®ç”Ÿæˆ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®
```bash
pip install -r requirements.txt
```

### æ•°æ®ä¸æ¨¡å‹ä¸‹è½½
- **æ¨¡å‹ã€ä»£ç ã€æ•°æ®ã€å®éªŒæŠ¥å‘Š**: [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1DheDYLMr1WUl1tcN_gpKuw?pwd=hr3k)
- **åŸºåº§æ¨¡å‹**: [MiniCPM4](https://github.com/OpenBMB/MiniCPM)

## ğŸ“Š æ•°æ®é›†

### 1. æœ¬åœ°ç”Ÿæˆæ•°æ® (HIT Dataset)
ä½¿ç”¨LLMç”Ÿæˆé«˜è´¨é‡çš„SFTæ•°æ®ï¼š
- **æ•°æ®ç”Ÿæˆæµç¨‹**:
  1. ä½¿ç”¨GPT-5è”ç½‘æœç´¢ç”Ÿæˆç›¸å…³ä¸»é¢˜ï¼Œå†™å…¥`topics.txt`
  2. å¼‚æ­¥è°ƒç”¨DeepSeekæ¨¡å‹ç”ŸæˆSFTæ•°æ®

### 2. å¼€æºæ•°æ®é›†
ä»[å¼€æºSFTæ•°æ®é›†æ•´ç†](https://github.com/chaoswork/sft_datasets)ä¸­é€‰å–ä»¥ä¸‹æ•°æ®
- [firefly_no_belle.json](https://github.com/chaoswork/sft_datasets)
- [Alpaca-CoT/firefly_no_belle](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT/blob/main/firefly/firefly_no_belle.json)

## ğŸ› ï¸ æ•°æ®ç”Ÿæˆ

### APIé…ç½®
æ”¯æŒä¸‰ç§çµæ´»çš„APIé…ç½®æ–¹å¼ï¼š

```bash
# 1. ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰
export OPENAI_API_KEY=ä½ çš„key
export OPENAI_BASE_URL=https://api.deepseek.com

# 2. å‚æ•°ä¼ å…¥
--api-key ä½ çš„key --base-url https://api.deepseek.com

# 3. ä»£ç å†…ä¿®æ”¹ï¼ˆæ‡’äººå¿…å¤‡ï¼‰
# ä¿®æ”¹ gen_SFT_data.py æ–‡ä»¶å¼€å¤´
```

### æ•°æ®ç”Ÿæˆå‘½ä»¤

**DeepSeek-Chatæ¨¡å‹ï¼ˆæ¨èï¼‰**:
```bash
python gen_SFT_data.py \
  --model deepseek-chat \
  --mode chat \
  --out data/raw/hit/train.jsonl \
  --n-per-topic 6 \
  --max-concurrency 50
```

**DeepSeek-Reasoneræ¨¡å‹**:
```bash
python gen_SFT_data.py \
  --model deepseek-reasoner \
  --mode reasoner \
  --out data/raw/hit/train.jsonl \
  --n-per-topic 6 \
  --max-concurrency 50
```

### ChatMLæ ¼å¼
```xml
<|beginofutterance|>ç³»ç»Ÿ
ï¼ˆInstructionï¼‰
<|endofutterance|>
<|beginofutterance|>ç”¨æˆ·
ï¼ˆQuestionï¼‰
<|endofutterance|>
<|beginofutterance|>æ™ºèƒ½åŠ©æ‰‹
ï¼ˆAnswerï¼‰
<|endofutterance|>
```

## ğŸ”§ æ•°æ®é¢„å¤„ç†

### ä¸»è¦å¤„ç†æ­¥éª¤
- æ ¼å¼è½¬æ¢ï¼šè½¬æ¢ä¸ºChatMLæ ¼å¼
- æ•°æ®æ¸…æ´—ä¸å»é‡
- æ•°æ®é›†åˆå¹¶ä¸é‡‡æ ·
- æ ¼å¼è½¬æ¢ï¼šè½¬æ¢ä¸ºFireflyè®­ç»ƒæ‰€éœ€çš„conversationæ ¼å¼

**æ³¨æ„**ï¼šåŠ æƒé‡‡æ ·åŠŸèƒ½å½“å‰æœªå®Œå…¨å®ç°ï¼Œéœ€è¦æ··åˆæ•°æ®é›†è°ƒæ•´é‡‡æ ·çš„ç”¨æˆ·å¯ä»¥è‡ªè¡Œä¿®æ”¹ç›¸å…³ä»£ç ã€‚å½“å‰ç‰ˆæœ¬ä¿è¯æ¸…æ´—å»é‡å’Œç›´æ¥åˆå¹¶åŠŸèƒ½ç¨³å®šã€‚

### é¢„å¤„ç†å‘½ä»¤
ç»è¿‡å……åˆ†æµ‹è¯•çš„é…ç½®ï¼ˆæ¸…æ´— + å»é‡ + åˆå¹¶ï¼‰ï¼š
```bash
python prep_sft_firefly_hit.py \
  --firefly-json /path/to/firefly_no_belle.json \
  --hit-jsonl /path/to/hit_ds_chat.jsonl \
  --out /path/to/output.jsonl \
  --total 300000 \
  --hit-ratio 0.4 \
  --max-firefly 250000 \
  --min-chinese-ratio 0.65 \
  --near-dup-threshold 3 \
  --drop-pii \
  --log INFO
```
**å…¸å‹è¾“å‡º**ï¼šçº¦171,739æ¡fireflyæ•°æ®å’Œ1,100æ¡hitæ•°æ®ï¼Œå»ºè®®æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´æ•°æ®é…æ–¹ã€‚

### æ ¼å¼è½¬æ¢
è½¬æ¢ä¸ºFireflyæ¡†æ¶SFTè®­ç»ƒæ‰€éœ€çš„conversationæ ¼å¼ï¼š
```bash
python chatml2conversation.py \
  --in /path/to/input.jsonl \
  --out /path/to/output.jsonl \
  --default-category "Brainstorming" \
  --start-id 1
```

## ğŸ¯ æ¨¡å‹è®­ç»ƒ

ä½¿ç”¨[Fireflyè®­ç»ƒæ¡†æ¶](https://github.com/yangjianxin1/Firefly)ï¼ŒOpenBMBçš„å¼€æºå·¥ç¨‹å¸ˆåœ¨PRä¸­æä¾›äº†è¯¦ç»†çš„MiniCPM4é…ç½®ã€‚

[Firefly](https://github.com/yangjianxin1/Firefly)æœ‰éå¸¸è¯¦ç»†çš„ä¸­æ–‡çš„**å‚æ•°è¯´æ˜**ä»¥åŠ**è®­ç»ƒç¤ºä¾‹**ï¼Œå»ºè®®å‚è€ƒ

### è®­ç»ƒæ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æ˜¾å­˜å ç”¨ | è®­ç»ƒé€Ÿåº¦ | æ¨èåº¦ |
|------|----------|----------|--------|
| Full Fine-tuning | é«˜ | æ…¢ | â­â­ |
| LoRA | ä¸­ | ä¸­ | â­â­â­ |
| **QLoRA** | **ä½** | **å¿«** | **â­â­â­â­â­** |

### QLoRAè®­ç»ƒæ­¥éª¤ï¼ˆLoRAï¼ŒFullåŒç†ï¼Œæ³¨æ„Fullå¯å¼€å¯deepspeedï¼Œå‘½ä»¤å¤´åŠ å…¥deepspeed --num_gpus={num_gpus} ï¼‰
1. **é…ç½®ä¿®æ”¹**:
   ```bash
   # ç¼–è¾‘é…ç½®æ–‡ä»¶
   vim Firefly/train_args/sft/qlora/minicpm4-0.5b-sft-qlora.json
   ```

2. **å¼€å§‹è®­ç»ƒ**:
   ```bash
   cd Firefly
   python train.py --train_args_file train_args/sft/qlora/minicpm4-0.5b-sft-qlora.json
   ```

### å…¶ä»–è®­ç»ƒæ–¹å¼
1. **LoRA**: ç±»ä¼¼QLoRAï¼Œä¿®æ”¹å¯¹åº”é…ç½®æ–‡ä»¶
2. **å…¨é‡å‚æ•°(Full)**: å¯å¼€å¯DeepSpeedä¼˜åŒ–ï¼Œnum_gpusæ›¿æ¢ä¸ºæ˜¾å¡æ•°é‡
   ```bash
   deepspeed --num_gpus={num_gpus} train.py --train_args_file train_args/sft/full/bloom-1b1-sft-full.json
   ```

### äºŒé˜¶æ®µè®­ç»ƒ
æœ¬é¡¹ç›®é‡‡ç”¨äºŒé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š
- **ç¬¬ä¸€é˜¶æ®µ**: ä½¿ç”¨å¤§è§„æ¨¡é€šç”¨æ•°æ®ï¼ˆfirefly_no_belleï¼‰å»ºç«‹åŸºç¡€èƒ½åŠ›
- **ç¬¬äºŒé˜¶æ®µ**: ä½¿ç”¨å°è§„æ¨¡ç§æœ‰æ•°æ®ï¼ˆHITæ•°æ®ï¼‰è¿›è¡Œé¢†åŸŸé£æ ¼å¼ºåŒ–
å¦‚éœ€å•é˜¶æ®µæ··åˆè®­ç»ƒï¼Œè¯·ç›¸åº”è°ƒæ•´æ•°æ®é…æ–¹æ¯”ä¾‹ã€‚

### æ¨¡å‹åˆå¹¶
QLoRA/LoRAè®­ç»ƒå®Œæˆåéœ€è¦åˆå¹¶æƒé‡ï¼Œä¾¿äºä¸‹ä¸€é˜¶æ®µè®­ç»ƒï¼š
```bash
python Firefly/script/merge_lora.py
```

## ğŸ” æ¨¡å‹æ¨ç†

åŸºäº[MiniCPM4å®˜æ–¹å®ç°](https://github.com/OpenBMB/MiniCPM)ï¼Œå¤ç°äº†ä¸‰ç§ä¸»æµæ¨ç†æ¡†æ¶ï¼š

### å¿«é€Ÿæµ‹è¯•
```bash
python quick_infer_local.py
```

### Transformersæ¨ç†ï¼ˆå…¼å®¹æ€§å¥½ï¼‰
```bash
python inference_with_transformers.py
```

### vLLMæ¨ç†ï¼ˆé«˜ååé‡ï¼‰
```bash
python inference_with_vLLM.py
```

### SGLangæ¨ç†ï¼ˆä¼˜åŒ–æ¨ç†æµç¨‹ï¼‰
```bash
python inference_with_SGLang.py
```

## ğŸ“ é¡¹ç›®ç»“æ„
```
â”œâ”€â”€ LLM_data_gen/           # æ•°æ®ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # åŸå§‹æ•°æ®
â”‚   â””â”€â”€ processed/         # å¤„ç†åçš„æ•°æ®
â”œâ”€â”€ scripts/               # è®­ç»ƒå’Œæ¨ç†è„šæœ¬
â”œâ”€â”€ configs/               # è®­ç»ƒé…ç½®æ–‡ä»¶
â””â”€â”€ models/                # è®­ç»ƒå¥½çš„æ¨¡å‹
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®é‡‡æ ·**: å½“å‰ç‰ˆæœ¬åŠ æƒé‡‡æ ·åŠŸèƒ½å°šæœªå®ç°ï¼Œéœ€è¦è‡ªå®šä¹‰é‡‡æ ·ç­–ç•¥çš„ç”¨æˆ·è¯·ä¿®æ”¹prep_sft_firefly_hit.pyä¸­çš„ç›¸å…³é€»è¾‘
2. **APIé™åˆ¶**: æ•°æ®ç”Ÿæˆæ—¶æ³¨æ„APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œåˆç†è®¾ç½®å¹¶å‘æ•°ï¼Œmax_concurrency=50åœ¨å®é™…æµ‹è¯•ä¸­è¡¨ç°ç¨³å®š
3. **ç¡¬ä»¶è¦æ±‚**: 
  - QLoRAè®­ç»ƒMiniCPM4-0.5Bï¼šæœ€ä½2.2GBæ˜¾å­˜
  - å®éªŒç¯å¢ƒï¼š16æ ¸CPU + å•å¡RTX 4090
  - è®­ç»ƒæ—¶é—´ï¼šQLoRAçº¦4å°æ—¶å®Œæˆè®­ç»ƒ
4. **æ¨¡å‹åˆå¹¶**: QLoRA/LoRAè®­ç»ƒå®Œæˆåè¯·ä½¿ç”¨`merge_lora.py`åˆå¹¶æ¨¡å‹, æ–¹ä¾¿ç¬¬äºŒé˜¶æ®µè®­ç»ƒå’Œæ¨ç†


## ğŸ“ˆ å®éªŒç»“æœ

è¯¦ç»†å®éªŒç»“æœå’Œåˆ†æè¯·å‚è€ƒå®éªŒæŠ¥å‘Šï¼ˆç™¾åº¦ç½‘ç›˜ä¸­æä¾›ï¼‰ã€‚

## ğŸ™ è‡´è°¢

- [MiniCPM](https://github.com/OpenBMB/MiniCPM) - ä¼˜ç§€çš„å¼€æºåŸºåº§æ¨¡å‹å‹
- [Firefly](https://github.com/yangjianxin1/Firefly) - æ˜“ç”¨é«˜æ•ˆçš„è®­ç»ƒæ¡†æ¶
- æˆ‘çš„é’±åŒ… - ä¸ºAPIè°ƒç”¨å’Œç®—åŠ›æä¾›èµ„é‡‘æ”¯æŒ

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚
