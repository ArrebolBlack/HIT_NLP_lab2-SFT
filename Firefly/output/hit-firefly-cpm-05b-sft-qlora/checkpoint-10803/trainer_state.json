{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 10803,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009256687957048967,
      "grad_norm": 0.1865387111902237,
      "learning_rate": 9.900000000000001e-05,
      "loss": 4.807,
      "step": 100
    },
    {
      "epoch": 0.018513375914097935,
      "grad_norm": 0.13895128667354584,
      "learning_rate": 0.000199,
      "loss": 3.7864,
      "step": 200
    },
    {
      "epoch": 0.027770063871146902,
      "grad_norm": 0.15064184367656708,
      "learning_rate": 0.0002,
      "loss": 3.7052,
      "step": 300
    },
    {
      "epoch": 0.03702675182819587,
      "grad_norm": 0.16535450518131256,
      "learning_rate": 0.0002,
      "loss": 3.6414,
      "step": 400
    },
    {
      "epoch": 0.04628343978524484,
      "grad_norm": 0.1743365377187729,
      "learning_rate": 0.0002,
      "loss": 3.6099,
      "step": 500
    },
    {
      "epoch": 0.055540127742293804,
      "grad_norm": 0.15282858908176422,
      "learning_rate": 0.0002,
      "loss": 3.5995,
      "step": 600
    },
    {
      "epoch": 0.06479681569934277,
      "grad_norm": 0.18245723843574524,
      "learning_rate": 0.0002,
      "loss": 3.5843,
      "step": 700
    },
    {
      "epoch": 0.07405350365639174,
      "grad_norm": 0.171697199344635,
      "learning_rate": 0.0002,
      "loss": 3.5837,
      "step": 800
    },
    {
      "epoch": 0.0833101916134407,
      "grad_norm": 0.19359520077705383,
      "learning_rate": 0.0002,
      "loss": 3.5547,
      "step": 900
    },
    {
      "epoch": 0.09256687957048967,
      "grad_norm": 0.19257359206676483,
      "learning_rate": 0.0002,
      "loss": 3.5609,
      "step": 1000
    },
    {
      "epoch": 0.10182356752753864,
      "grad_norm": 0.2276061326265335,
      "learning_rate": 0.0002,
      "loss": 3.5123,
      "step": 1100
    },
    {
      "epoch": 0.11108025548458761,
      "grad_norm": 0.2074807733297348,
      "learning_rate": 0.0002,
      "loss": 3.4912,
      "step": 1200
    },
    {
      "epoch": 0.12033694344163658,
      "grad_norm": 0.18059343099594116,
      "learning_rate": 0.0002,
      "loss": 3.4908,
      "step": 1300
    },
    {
      "epoch": 0.12959363139868554,
      "grad_norm": 0.1931028813123703,
      "learning_rate": 0.0002,
      "loss": 3.4576,
      "step": 1400
    },
    {
      "epoch": 0.13885031935573452,
      "grad_norm": 0.2792060077190399,
      "learning_rate": 0.0002,
      "loss": 3.4644,
      "step": 1500
    },
    {
      "epoch": 0.14810700731278348,
      "grad_norm": 0.1954384446144104,
      "learning_rate": 0.0002,
      "loss": 3.4774,
      "step": 1600
    },
    {
      "epoch": 0.15736369526983246,
      "grad_norm": 0.22795772552490234,
      "learning_rate": 0.0002,
      "loss": 3.4545,
      "step": 1700
    },
    {
      "epoch": 0.1666203832268814,
      "grad_norm": 0.26594334840774536,
      "learning_rate": 0.0002,
      "loss": 3.4465,
      "step": 1800
    },
    {
      "epoch": 0.1758770711839304,
      "grad_norm": 0.23137004673480988,
      "learning_rate": 0.0002,
      "loss": 3.4531,
      "step": 1900
    },
    {
      "epoch": 0.18513375914097935,
      "grad_norm": 0.2202725112438202,
      "learning_rate": 0.0002,
      "loss": 3.4292,
      "step": 2000
    },
    {
      "epoch": 0.19439044709802833,
      "grad_norm": 0.24475227296352386,
      "learning_rate": 0.0002,
      "loss": 3.4242,
      "step": 2100
    },
    {
      "epoch": 0.20364713505507728,
      "grad_norm": 0.19305013120174408,
      "learning_rate": 0.0002,
      "loss": 3.4286,
      "step": 2200
    },
    {
      "epoch": 0.21290382301212626,
      "grad_norm": 0.21183116734027863,
      "learning_rate": 0.0002,
      "loss": 3.4266,
      "step": 2300
    },
    {
      "epoch": 0.22216051096917522,
      "grad_norm": 0.25289610028266907,
      "learning_rate": 0.0002,
      "loss": 3.4227,
      "step": 2400
    },
    {
      "epoch": 0.2314171989262242,
      "grad_norm": 0.2324800044298172,
      "learning_rate": 0.0002,
      "loss": 3.3436,
      "step": 2500
    },
    {
      "epoch": 0.24067388688327315,
      "grad_norm": 0.2803055942058563,
      "learning_rate": 0.0002,
      "loss": 3.38,
      "step": 2600
    },
    {
      "epoch": 0.24993057484032213,
      "grad_norm": 0.22412165999412537,
      "learning_rate": 0.0002,
      "loss": 3.3932,
      "step": 2700
    },
    {
      "epoch": 0.2591872627973711,
      "grad_norm": 0.2225501388311386,
      "learning_rate": 0.0002,
      "loss": 3.3693,
      "step": 2800
    },
    {
      "epoch": 0.26844395075442007,
      "grad_norm": 0.22877399623394012,
      "learning_rate": 0.0002,
      "loss": 3.3356,
      "step": 2900
    },
    {
      "epoch": 0.27770063871146905,
      "grad_norm": 0.2331651896238327,
      "learning_rate": 0.0002,
      "loss": 3.3529,
      "step": 3000
    },
    {
      "epoch": 0.28695732666851803,
      "grad_norm": 0.22163397073745728,
      "learning_rate": 0.0002,
      "loss": 3.3537,
      "step": 3100
    },
    {
      "epoch": 0.29621401462556696,
      "grad_norm": 0.22375193238258362,
      "learning_rate": 0.0002,
      "loss": 3.3592,
      "step": 3200
    },
    {
      "epoch": 0.30547070258261594,
      "grad_norm": 0.25483521819114685,
      "learning_rate": 0.0002,
      "loss": 3.3803,
      "step": 3300
    },
    {
      "epoch": 0.3147273905396649,
      "grad_norm": 0.25293928384780884,
      "learning_rate": 0.0002,
      "loss": 3.3237,
      "step": 3400
    },
    {
      "epoch": 0.3239840784967139,
      "grad_norm": 0.23816034197807312,
      "learning_rate": 0.0002,
      "loss": 3.3283,
      "step": 3500
    },
    {
      "epoch": 0.3332407664537628,
      "grad_norm": 0.2392086237668991,
      "learning_rate": 0.0002,
      "loss": 3.3235,
      "step": 3600
    },
    {
      "epoch": 0.3424974544108118,
      "grad_norm": 0.2742631435394287,
      "learning_rate": 0.0002,
      "loss": 3.3177,
      "step": 3700
    },
    {
      "epoch": 0.3517541423678608,
      "grad_norm": 0.22237731516361237,
      "learning_rate": 0.0002,
      "loss": 3.278,
      "step": 3800
    },
    {
      "epoch": 0.36101083032490977,
      "grad_norm": 0.2850240468978882,
      "learning_rate": 0.0002,
      "loss": 3.2795,
      "step": 3900
    },
    {
      "epoch": 0.3702675182819587,
      "grad_norm": 0.25051233172416687,
      "learning_rate": 0.0002,
      "loss": 3.2728,
      "step": 4000
    },
    {
      "epoch": 0.3795242062390077,
      "grad_norm": 0.21510471403598785,
      "learning_rate": 0.0002,
      "loss": 3.2444,
      "step": 4100
    },
    {
      "epoch": 0.38878089419605666,
      "grad_norm": 0.28696364164352417,
      "learning_rate": 0.0002,
      "loss": 3.2865,
      "step": 4200
    },
    {
      "epoch": 0.39803758215310564,
      "grad_norm": 0.27150672674179077,
      "learning_rate": 0.0002,
      "loss": 3.2387,
      "step": 4300
    },
    {
      "epoch": 0.40729427011015457,
      "grad_norm": 0.3065176010131836,
      "learning_rate": 0.0002,
      "loss": 3.1955,
      "step": 4400
    },
    {
      "epoch": 0.41655095806720355,
      "grad_norm": 0.2244543880224228,
      "learning_rate": 0.0002,
      "loss": 3.2763,
      "step": 4500
    },
    {
      "epoch": 0.42580764602425253,
      "grad_norm": 0.23403364419937134,
      "learning_rate": 0.0002,
      "loss": 3.2503,
      "step": 4600
    },
    {
      "epoch": 0.4350643339813015,
      "grad_norm": 0.28916653990745544,
      "learning_rate": 0.0002,
      "loss": 3.2628,
      "step": 4700
    },
    {
      "epoch": 0.44432102193835044,
      "grad_norm": 0.28120553493499756,
      "learning_rate": 0.0002,
      "loss": 3.2684,
      "step": 4800
    },
    {
      "epoch": 0.4535777098953994,
      "grad_norm": 0.20448297262191772,
      "learning_rate": 0.0002,
      "loss": 3.2435,
      "step": 4900
    },
    {
      "epoch": 0.4628343978524484,
      "grad_norm": 0.2720187306404114,
      "learning_rate": 0.0002,
      "loss": 3.2312,
      "step": 5000
    },
    {
      "epoch": 0.4720910858094974,
      "grad_norm": 0.3577088415622711,
      "learning_rate": 0.0002,
      "loss": 3.2448,
      "step": 5100
    },
    {
      "epoch": 0.4813477737665463,
      "grad_norm": 0.22663934528827667,
      "learning_rate": 0.0002,
      "loss": 3.2093,
      "step": 5200
    },
    {
      "epoch": 0.4906044617235953,
      "grad_norm": 0.27247634530067444,
      "learning_rate": 0.0002,
      "loss": 3.2352,
      "step": 5300
    },
    {
      "epoch": 0.49986114968064427,
      "grad_norm": 0.2508929371833801,
      "learning_rate": 0.0002,
      "loss": 3.227,
      "step": 5400
    },
    {
      "epoch": 0.5091178376376932,
      "grad_norm": 0.24232538044452667,
      "learning_rate": 0.0002,
      "loss": 3.2088,
      "step": 5500
    },
    {
      "epoch": 0.5183745255947422,
      "grad_norm": 0.2332744598388672,
      "learning_rate": 0.0002,
      "loss": 3.2288,
      "step": 5600
    },
    {
      "epoch": 0.5276312135517912,
      "grad_norm": 0.283412903547287,
      "learning_rate": 0.0002,
      "loss": 3.2124,
      "step": 5700
    },
    {
      "epoch": 0.5368879015088401,
      "grad_norm": 0.26868805289268494,
      "learning_rate": 0.0002,
      "loss": 3.1918,
      "step": 5800
    },
    {
      "epoch": 0.5461445894658891,
      "grad_norm": 0.27762508392333984,
      "learning_rate": 0.0002,
      "loss": 3.1713,
      "step": 5900
    },
    {
      "epoch": 0.5554012774229381,
      "grad_norm": 0.27222171425819397,
      "learning_rate": 0.0002,
      "loss": 3.1253,
      "step": 6000
    },
    {
      "epoch": 0.564657965379987,
      "grad_norm": 0.2454007863998413,
      "learning_rate": 0.0002,
      "loss": 3.1266,
      "step": 6100
    },
    {
      "epoch": 0.5739146533370361,
      "grad_norm": 0.32276782393455505,
      "learning_rate": 0.0002,
      "loss": 3.174,
      "step": 6200
    },
    {
      "epoch": 0.583171341294085,
      "grad_norm": 0.2663193345069885,
      "learning_rate": 0.0002,
      "loss": 3.1555,
      "step": 6300
    },
    {
      "epoch": 0.5924280292511339,
      "grad_norm": 0.23612822592258453,
      "learning_rate": 0.0002,
      "loss": 3.1411,
      "step": 6400
    },
    {
      "epoch": 0.601684717208183,
      "grad_norm": 0.3399079740047455,
      "learning_rate": 0.0002,
      "loss": 3.1602,
      "step": 6500
    },
    {
      "epoch": 0.6109414051652319,
      "grad_norm": 0.2930276095867157,
      "learning_rate": 0.0002,
      "loss": 3.1309,
      "step": 6600
    },
    {
      "epoch": 0.6201980931222808,
      "grad_norm": 0.2435845285654068,
      "learning_rate": 0.0002,
      "loss": 3.1377,
      "step": 6700
    },
    {
      "epoch": 0.6294547810793298,
      "grad_norm": 0.2536839544773102,
      "learning_rate": 0.0002,
      "loss": 3.1821,
      "step": 6800
    },
    {
      "epoch": 0.6387114690363788,
      "grad_norm": 0.26979726552963257,
      "learning_rate": 0.0002,
      "loss": 3.1519,
      "step": 6900
    },
    {
      "epoch": 0.6479681569934278,
      "grad_norm": 0.26863932609558105,
      "learning_rate": 0.0002,
      "loss": 3.1451,
      "step": 7000
    },
    {
      "epoch": 0.6572248449504767,
      "grad_norm": 0.3839576542377472,
      "learning_rate": 0.0002,
      "loss": 3.1221,
      "step": 7100
    },
    {
      "epoch": 0.6664815329075257,
      "grad_norm": 0.2933410704135895,
      "learning_rate": 0.0002,
      "loss": 3.1317,
      "step": 7200
    },
    {
      "epoch": 0.6757382208645747,
      "grad_norm": 0.29926326870918274,
      "learning_rate": 0.0002,
      "loss": 3.1219,
      "step": 7300
    },
    {
      "epoch": 0.6849949088216236,
      "grad_norm": 0.2557748556137085,
      "learning_rate": 0.0002,
      "loss": 3.141,
      "step": 7400
    },
    {
      "epoch": 0.6942515967786725,
      "grad_norm": 0.248946875333786,
      "learning_rate": 0.0002,
      "loss": 3.0988,
      "step": 7500
    },
    {
      "epoch": 0.7035082847357216,
      "grad_norm": 0.2963470220565796,
      "learning_rate": 0.0002,
      "loss": 3.071,
      "step": 7600
    },
    {
      "epoch": 0.7127649726927705,
      "grad_norm": 0.3083944320678711,
      "learning_rate": 0.0002,
      "loss": 3.1303,
      "step": 7700
    },
    {
      "epoch": 0.7220216606498195,
      "grad_norm": 0.27998682856559753,
      "learning_rate": 0.0002,
      "loss": 3.1423,
      "step": 7800
    },
    {
      "epoch": 0.7312783486068685,
      "grad_norm": 0.28488919138908386,
      "learning_rate": 0.0002,
      "loss": 3.0916,
      "step": 7900
    },
    {
      "epoch": 0.7405350365639174,
      "grad_norm": 0.2721624970436096,
      "learning_rate": 0.0002,
      "loss": 3.159,
      "step": 8000
    },
    {
      "epoch": 0.7497917245209664,
      "grad_norm": 0.3003568649291992,
      "learning_rate": 0.0002,
      "loss": 3.0575,
      "step": 8100
    },
    {
      "epoch": 0.7590484124780154,
      "grad_norm": 0.24646560847759247,
      "learning_rate": 0.0002,
      "loss": 3.1927,
      "step": 8200
    },
    {
      "epoch": 0.7683051004350643,
      "grad_norm": 0.27313560247421265,
      "learning_rate": 0.0002,
      "loss": 3.117,
      "step": 8300
    },
    {
      "epoch": 0.7775617883921133,
      "grad_norm": 0.26800188422203064,
      "learning_rate": 0.0002,
      "loss": 3.1206,
      "step": 8400
    },
    {
      "epoch": 0.7868184763491622,
      "grad_norm": 0.2504110634326935,
      "learning_rate": 0.0002,
      "loss": 3.0467,
      "step": 8500
    },
    {
      "epoch": 0.7960751643062113,
      "grad_norm": 0.289051353931427,
      "learning_rate": 0.0002,
      "loss": 3.122,
      "step": 8600
    },
    {
      "epoch": 0.8053318522632602,
      "grad_norm": 0.2748611569404602,
      "learning_rate": 0.0002,
      "loss": 3.0705,
      "step": 8700
    },
    {
      "epoch": 0.8145885402203091,
      "grad_norm": 0.24728398025035858,
      "learning_rate": 0.0002,
      "loss": 3.1112,
      "step": 8800
    },
    {
      "epoch": 0.8238452281773582,
      "grad_norm": 0.2603730857372284,
      "learning_rate": 0.0002,
      "loss": 3.0633,
      "step": 8900
    },
    {
      "epoch": 0.8331019161344071,
      "grad_norm": 0.3087427318096161,
      "learning_rate": 0.0002,
      "loss": 3.0584,
      "step": 9000
    },
    {
      "epoch": 0.8423586040914561,
      "grad_norm": 0.22371608018875122,
      "learning_rate": 0.0002,
      "loss": 3.0884,
      "step": 9100
    },
    {
      "epoch": 0.8516152920485051,
      "grad_norm": 0.2723254859447479,
      "learning_rate": 0.0002,
      "loss": 3.0421,
      "step": 9200
    },
    {
      "epoch": 0.860871980005554,
      "grad_norm": 0.37334659695625305,
      "learning_rate": 0.0002,
      "loss": 3.033,
      "step": 9300
    },
    {
      "epoch": 0.870128667962603,
      "grad_norm": 0.2796354293823242,
      "learning_rate": 0.0002,
      "loss": 3.0557,
      "step": 9400
    },
    {
      "epoch": 0.879385355919652,
      "grad_norm": 0.3220363259315491,
      "learning_rate": 0.0002,
      "loss": 3.0887,
      "step": 9500
    },
    {
      "epoch": 0.8886420438767009,
      "grad_norm": 0.3096471130847931,
      "learning_rate": 0.0002,
      "loss": 3.064,
      "step": 9600
    },
    {
      "epoch": 0.8978987318337499,
      "grad_norm": 0.288669228553772,
      "learning_rate": 0.0002,
      "loss": 3.0722,
      "step": 9700
    },
    {
      "epoch": 0.9071554197907988,
      "grad_norm": 0.2928049862384796,
      "learning_rate": 0.0002,
      "loss": 3.053,
      "step": 9800
    },
    {
      "epoch": 0.9164121077478479,
      "grad_norm": 0.24392351508140564,
      "learning_rate": 0.0002,
      "loss": 3.0425,
      "step": 9900
    },
    {
      "epoch": 0.9256687957048968,
      "grad_norm": 0.26880088448524475,
      "learning_rate": 0.0002,
      "loss": 3.0438,
      "step": 10000
    },
    {
      "epoch": 0.9349254836619457,
      "grad_norm": 0.290375292301178,
      "learning_rate": 0.0002,
      "loss": 3.109,
      "step": 10100
    },
    {
      "epoch": 0.9441821716189948,
      "grad_norm": 0.3041051924228668,
      "learning_rate": 0.0002,
      "loss": 2.9706,
      "step": 10200
    },
    {
      "epoch": 0.9534388595760437,
      "grad_norm": 0.29724085330963135,
      "learning_rate": 0.0002,
      "loss": 3.0041,
      "step": 10300
    },
    {
      "epoch": 0.9626955475330926,
      "grad_norm": 0.2712574303150177,
      "learning_rate": 0.0002,
      "loss": 3.0157,
      "step": 10400
    },
    {
      "epoch": 0.9719522354901416,
      "grad_norm": 0.2502809762954712,
      "learning_rate": 0.0002,
      "loss": 3.042,
      "step": 10500
    },
    {
      "epoch": 0.9812089234471906,
      "grad_norm": 0.4239885210990906,
      "learning_rate": 0.0002,
      "loss": 3.0335,
      "step": 10600
    },
    {
      "epoch": 0.9904656114042396,
      "grad_norm": 0.27651578187942505,
      "learning_rate": 0.0002,
      "loss": 3.0243,
      "step": 10700
    },
    {
      "epoch": 0.9997222993612885,
      "grad_norm": 0.2807818055152893,
      "learning_rate": 0.0002,
      "loss": 2.9966,
      "step": 10800
    }
  ],
  "logging_steps": 100,
  "max_steps": 10803,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.518436724859597e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
